{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IwiXUW2Tp3jY",
        "KdTbl79Sp-Wv",
        "6N4SnjGJruEe",
        "8fn0WHxksANf",
        "DpRa9sesBeGt",
        "ne0xvdQpBaRy",
        "dEK5YPSJEYn0",
        "42ircIwdEei9",
        "0KR8AUItsY_G",
        "TE7iqFmesmY8",
        "4o9_tVWvc5la",
        "6AhT_4VcswXo",
        "VDkX3-pKfJcL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install and Import"
      ],
      "metadata": {
        "id": "IwiXUW2Tp3jY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ijUUME_pvH9",
        "outputId": "e7613406-c809-43e3-8fe7-287249d4e292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypi (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q rdkit pypi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem.Draw import IPythonConsole, MolsToGridImage\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "RDLogger.DisableLog(\"rdApp.*\")"
      ],
      "metadata": {
        "id": "heOJRdA2p23S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "KdTbl79Sp-Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataHelper():\n",
        "    def __init__(self):\n",
        "        csv_path = tf.keras.utils.get_file(\"qm9.csv\", \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\")\n",
        "        self.data = list()\n",
        "        with open(csv_path, \"r\")  as fin:\n",
        "            for line in fin.readlines()[1:]:\n",
        "                self.data.append(line.split(\",\")[1])\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        smiles = self.data[idx]\n",
        "        print(f\"SMILES: {smiles}\")\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        print(f\"Number of Heavy Atoms: {mol.GetNumHeavyAtoms()}\")\n",
        "        return mol"
      ],
      "metadata": {
        "id": "7ipVEFo-p_jO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DH = DataHelper()"
      ],
      "metadata": {
        "id": "e8K3CcLCrTnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d0fc4d-0352-4d83-d0e7-90ad75a3c45b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\n",
            "29856825/29856825 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "6N4SnjGJruEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atom_mapping = {\n",
        "    \"C\": 0,\n",
        "    0: \"C\",\n",
        "    \"N\": 1,\n",
        "    1: \"N\",\n",
        "    \"O\": 2,\n",
        "    2: \"O\",\n",
        "    \"F\": 3,\n",
        "    3: \"F\",\n",
        "}\n",
        "\n",
        "bond_mapping = {\n",
        "    \"SINGLE\": 0,\n",
        "    0: Chem.BondType.SINGLE,\n",
        "    \"DOUBLE\": 1,\n",
        "    1: Chem.BondType.DOUBLE,\n",
        "    \"TRIPLE\": 2,\n",
        "    2: Chem.BondType.TRIPLE,\n",
        "    \"AROMATIC\": 3,\n",
        "    3: Chem.BondType.AROMATIC,\n",
        "}\n",
        "\n",
        "NUM_ATOMS = 9  # Maximum number of atoms\n",
        "ATOM_DIM = 4 + 1  # Number of atom types\n",
        "BOND_DIM = 4 + 1  # Number of bond types\n",
        "LATENT_DIM = 64  # Size of the latent space\n",
        "\n",
        "\n",
        "def smiles_to_graph(smiles):\n",
        "    # Converts SMILES to molecule object\n",
        "    molecule = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    # Initialize adjacency and feature tensor\n",
        "    adjacency = np.zeros((BOND_DIM, NUM_ATOMS, NUM_ATOMS), \"float32\")\n",
        "    features = np.zeros((NUM_ATOMS, ATOM_DIM), \"float32\")\n",
        "\n",
        "    # loop over each atom in molecule\n",
        "    for atom in molecule.GetAtoms():\n",
        "        i = atom.GetIdx()\n",
        "        atom_type = atom_mapping[atom.GetSymbol()]\n",
        "        features[i] = np.eye(ATOM_DIM)[atom_type]\n",
        "        # loop over one-hop neighbors\n",
        "        for neighbor in atom.GetNeighbors():\n",
        "            j = neighbor.GetIdx()\n",
        "            bond = molecule.GetBondBetweenAtoms(i, j)\n",
        "            bond_type_idx = bond_mapping[bond.GetBondType().name]\n",
        "            adjacency[bond_type_idx, [i, j], [j, i]] = 1\n",
        "\n",
        "    # Where no bond, add 1 to last channel (indicating \"non-bond\")\n",
        "    # Notice: channels-first\n",
        "    adjacency[-1, np.sum(adjacency, axis=0) == 0] = 1\n",
        "\n",
        "    # Where no atom, add 1 to last column (indicating \"non-atom\")\n",
        "    features[np.where(np.sum(features, axis=1) == 0)[0], -1] = 1\n",
        "\n",
        "    return adjacency, features\n",
        "\n",
        "\n",
        "def graph_to_molecule(graph):\n",
        "    # Unpack graph\n",
        "    adjacency, features = graph\n",
        "\n",
        "    # RWMol is a molecule object intended to be edited\n",
        "    molecule = Chem.RWMol()\n",
        "\n",
        "    # Remove \"no atoms\" & atoms with no bonds\n",
        "    keep_idx = np.where(\n",
        "        (np.argmax(features, axis=1) != ATOM_DIM - 1)\n",
        "        & (np.sum(adjacency[:-1], axis=(0, 1)) != 0)\n",
        "    )[0]\n",
        "    features = features[keep_idx]\n",
        "    adjacency = adjacency[:, keep_idx, :][:, :, keep_idx]\n",
        "\n",
        "    # Add atoms to molecule\n",
        "    for atom_type_idx in np.argmax(features, axis=1):\n",
        "        atom = Chem.Atom(atom_mapping[atom_type_idx])\n",
        "        _ = molecule.AddAtom(atom)\n",
        "\n",
        "    # Add bonds between atoms in molecule; based on the upper triangles\n",
        "    # of the [symmetric] adjacency tensor\n",
        "    (bonds_ij, atoms_i, atoms_j) = np.where(np.triu(adjacency) == 1)\n",
        "    for (bond_ij, atom_i, atom_j) in zip(bonds_ij, atoms_i, atoms_j):\n",
        "        if atom_i == atom_j or bond_ij == BOND_DIM - 1:\n",
        "            continue\n",
        "        bond_type = bond_mapping[bond_ij]\n",
        "        molecule.AddBond(int(atom_i), int(atom_j), bond_type)\n",
        "\n",
        "    # Sanitize the molecule; for more information on sanitization, see\n",
        "    # https://www.rdkit.org/docs/RDKit_Book.html#molecular-sanitization\n",
        "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
        "    # Let's be strict. If sanitization fails, return None\n",
        "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
        "        return None\n",
        "\n",
        "    return molecule"
      ],
      "metadata": {
        "id": "y0RD5YzArqgH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Training Set"
      ],
      "metadata": {
        "id": "8fn0WHxksANf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_tensor, feature_tensor = [], []\n",
        "for smiles in DH.data[::10]:\n",
        "    adjacency, features = smiles_to_graph(smiles)\n",
        "    adjacency_tensor.append(adjacency)\n",
        "    feature_tensor.append(features)\n",
        "\n",
        "adjacency_tensor = np.array(adjacency_tensor)\n",
        "feature_tensor = np.array(feature_tensor)\n",
        "\n",
        "print(\"adjacency_tensor.shape =\", adjacency_tensor.shape)\n",
        "print(\"feature_tensor.shape =\", feature_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJxvQoAwr_Mm",
        "outputId": "0b2c217a-8719-4023-8809-4c0720da29e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adjacency_tensor.shape = (13389, 5, 9, 9)\n",
            "feature_tensor.shape = (13389, 9, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Generator"
      ],
      "metadata": {
        "id": "DpRa9sesBeGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantum Dense Layer"
      ],
      "metadata": {
        "id": "ne0xvdQpBaRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extra Utilities/Imports"
      ],
      "metadata": {
        "id": "dEK5YPSJEYn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q qiskit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1cwngY6CAOU",
        "outputId": "792132ac-c769-40a8-9044-f93c51c4492e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m241.5/241.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.5/37.5 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for qiskit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import qiskit"
      ],
      "metadata": {
        "id": "uEW8VQvzC3uv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import transpile, assemble, QuantumRegister, QuantumCircuit\n",
        "from qiskit.providers.ibmq import least_busy\n",
        "from qiskit.providers.ibmq.job import job_monitor\n",
        "from qiskit.tools import backend_monitor"
      ],
      "metadata": {
        "id": "K_DritdACH6M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### IDK what these functions do"
      ],
      "metadata": {
        "id": "gO0a4CqvEbIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quantum Dense Layer"
      ],
      "metadata": {
        "id": "42ircIwdEei9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantumLayer(keras.layers.Layer):\n",
        "    def __init__(self, qubits=16, instructions=None, shots=2, use_parameter_shift_gradient_flow=False):\n",
        "        super(QuantumLayer, self).__init__()\n",
        "        self.use_parameter_shift_gradient_flow = use_parameter_shift_gradient_flow\n",
        "        self.qubits = qubits\n",
        "        self.instructions = instructions\n",
        "        self.tensor_history = []\n",
        "        self.shots = shots\n",
        "        self.circuit = QiskitCircuitModule(self.qubits, instructions=self.instructions, shots=self.shots)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        kernel_p_initialisation = tf.random_normal_initializer()\n",
        "        self.kernel_p = tf.Variable(name=\"kernel_p\", initial_value=kernel_p_initialisation(shape=(input_shape[-1], self.qubits), dtype='float32'), trainable=True)\n",
        "        kernel_phi_initialisation = tf.zeros_initializer()\n",
        "        self.kernel_phi = tf.Variable(name=\"kernel_phi\", initial_value=kernel_phi_initialisation(shape=(self.qubits,), dtype='float32'), trainable=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if not self.use_parameter_shift_gradient_flow:\n",
        "            output = tf.matmul(inputs, self.kernel_p)\n",
        "            print(output)\n",
        "            qubit_output = self.circuit.quantum_execute(tf.reshape(output, [1, self.qubits]), self.kernel_phi)\n",
        "            qubit_output = tf.reshape(tf.convert_to_tensor(qubit_output), (1, 1, self.qubits))\n",
        "            output += (qubit_output - output)\n",
        "        else: output = self.quantum_flow(inputs)\n",
        "        return output\n",
        "\n",
        "    @tf.custom_gradient\n",
        "    def quantum_flow(self, x):\n",
        "        output = tf.matmul(x, self.kernel_p)\n",
        "        qubit_output = tf.reshape(tf.convert_to_tensor(self.circuit.quantum_execute(tf.reshape(output, [1, self.qubits]), self.kernel_phi)), (1, 1, self.qubits))\n",
        "        output = qubit_output\n",
        "\n",
        "        def grad(dy, variables=None):\n",
        "            shift = np.pi / 2\n",
        "            shift_right = x + np.ones(x.shape) * shift\n",
        "            shift_left = x - np.ones(x.shape) * shift\n",
        "            input_left = tf.matmul(shift_left, self.kernel_p)\n",
        "            input_right = tf.matmul(shift_right, self.kernel_p)\n",
        "            output_right = self.circuit.quantum_execute(tf.reshape(input_right, [1, self.qubits]), self.kernel_phi)\n",
        "            output_left = self.circuit.quantum_execute(tf.reshape(input_left, [1, self.qubits]), self.kernel_phi)\n",
        "            quantum_gradient = [output_right[i] - output_left[i] for i in range(len(output_right))]\n",
        "            input_gradient = dy * quantum_gradient\n",
        "            dy_input_gradient = tf.reshape(tf.matmul(input_gradient, tf.transpose(self.kernel_p)), shape=[1, 1, x.get_shape().as_list()[-1]])\n",
        "            grd_w = []\n",
        "            for i in range(self.qubits):\n",
        "                w = self.kernel_p[:, i]\n",
        "                w += dy_input_gradient\n",
        "                grd_w.append(w)\n",
        "            tf_grd_w = tf.convert_to_tensor(grd_w)\n",
        "            tf_grd_w = tf.reshape(tf_grd_w, shape=(x.get_shape().as_list()[-1], self.qubits))\n",
        "            return dy_input_gradient, [tf_grd_w]\n",
        "\n",
        "        return output, grad"
      ],
      "metadata": {
        "id": "BCM_W3B9Es2W"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QiskitCircuitModule:\n",
        "    def __init__(self, qubits, instructions=None, execute_on_IBMQ=False, shots=2):\n",
        "        self.qubit_num = qubits\n",
        "        self.instructions = instructions\n",
        "        if not self.instructions:\n",
        "            self.instructions = self.null_circuit(self.qubit_num)\n",
        "        self.probabilities = tf.constant([[0.5] * self.qubit_num])\n",
        "        self.phase_probabilities = tf.constant([1] * self.qubit_num)\n",
        "        self.layer = self.superposition_qubits(self.probabilities, self.phase_probabilities)\n",
        "        self.layer.append(self.instructions, range(self.qubit_num))\n",
        "        self.layer.measure_all()\n",
        "        self.backend = qiskit.Aer.get_backend('aer_simulator')\n",
        "        self.shots = shots\n",
        "\n",
        "    def p_to_angle(self, p):\n",
        "        angle = 2 * np.arccos(np.sqrt(p))\n",
        "        return angle\n",
        "\n",
        "    def superposition_qubits(self, probabilities: tf.Tensor, phases: tf.Tensor):\n",
        "        layer = qiskit.QuantumCircuit(self.qubit_num)\n",
        "        reshaped_probabilities = tf.reshape(probabilities, [self.qubit_num])\n",
        "        reshaped_phases = tf.reshape(phases, [self.qubit_num])\n",
        "        static_probabilities = tf.get_static_value(reshaped_probabilities[:])\n",
        "        static_phases = tf.get_static_value(reshaped_phases[:])\n",
        "        for i in range(len(static_probabilities)):\n",
        "            p = static_probabilities[i]\n",
        "        #for ix, p in enumerate(static_probabilities):\n",
        "            p = np.abs(p)\n",
        "            theta = self.p_to_angle(p)\n",
        "            phi = self.p_to_angle(static_phases[i])\n",
        "            layer.u(theta, phi, 0, i)\n",
        "        return layer\n",
        "\n",
        "    def quantum_execute(self, probabilities, phases):\n",
        "        self.layer = self.superposition_qubits(probabilities, phases)\n",
        "        self.layer.append(self.instructions, range(self.qubit_num))\n",
        "        self.layer.measure_all()\n",
        "        transpiled_circuit = transpile(self.layer, self.backend)\n",
        "        quantum_job_object = assemble(transpiled_circuit, shots=self.shots)\n",
        "        quantum_job = self.backend.run(quantum_job_object)\n",
        "        result = quantum_job.result().get_counts()\n",
        "        qubit_set_probabilities = self.calculate_qubit_set_probabilities(result)\n",
        "        return qubit_set_probabilities\n",
        "\n",
        "    def calculate_qubit_set_probabilities(self, quantum_job_result):\n",
        "        qubit_set_probabilities = [0] * self.qubit_num\n",
        "        for state_result, count in quantum_job_result.items():\n",
        "            for ix, q in enumerate(state_result):\n",
        "                if q == '1':\n",
        "                    qubit_set_probabilities[ix] += count\n",
        "        sum_counts = sum(qubit_set_probabilities)\n",
        "        if not sum_counts == 0:\n",
        "            qubit_set_probabilities = [i/sum_counts for i in qubit_set_probabilities]\n",
        "        return qubit_set_probabilities\n",
        "\n",
        "    def null_circuit(self, qubits):\n",
        "        try:\n",
        "            gate_register = QuantumRegister(qubits, 'q')\n",
        "            gate_circuit = QuantumCircuit(gate_register, name='sub_circuit')\n",
        "            gate_instructions = gate_circuit.to_instruction()\n",
        "        except Exception as e: raise RuntimeError(\"ğŸ…µğŸ†„ğŸ…²ğŸ…º!\")\n",
        "        return gate_instructions"
      ],
      "metadata": {
        "id": "-ZnyG8AsBjH0"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Allah be praised IT WORKS"
      ],
      "metadata": {
        "id": "Z_58qeXME4Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sus = tf.constant([[0.345], ])"
      ],
      "metadata": {
        "id": "wniIxTLPVTGw"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphGenerator(keras.Model):\n",
        "    def __init__(self, dense_units, dropout_rate, latent_dim, adjacency_shape, feature_shape, param_shift=False,):\n",
        "        super(GraphGenerator, self).__init__()\n",
        "        self.z = keras.layers.Dense(latent_dim, input_shape=(1,2))\n",
        "        self.ql = QuantumLayer(dense_units, use_parameter_shift_gradient_flow=param_shift)\n",
        "        self.dropout = keras.layers.Dropout(dropout_rate)\n",
        "        self.latent_dim = latent_dim\n",
        "        self.adjacency_shape = adjacency_shape\n",
        "        self.feature_shape = feature_shape\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        x = self.z(input_tensor)\n",
        "        x = self.ql(x)\n",
        "        x = keras.activations.tanh(x)\n",
        "        x = self.dropout(x)\n",
        "        x_adjacency = keras.layers.Dense(tf.math.reduce_prod(self.adjacency_shape))(x)\n",
        "        x_adjacency = keras.layers.Reshape(self.adjacency_shape)(x_adjacency)\n",
        "        x_adjacency = (x_adjacency + tf.transpose(x_adjacency, (0, 1, 3, 2))) / 2\n",
        "        x_adjacency = keras.layers.Softmax(axis=1)(x_adjacency)\n",
        "        x_features = keras.layers.Dense(tf.math.reduce_prod(self.feature_shape))(x)\n",
        "        x_features = keras.layers.Reshape(self.feature_shape)(x_features)\n",
        "        x_features = keras.layers.Softmax(axis=2)(x_features)\n",
        "        return [x_adjacency, x_features]\n"
      ],
      "metadata": {
        "id": "8uSsFNdpL7D1"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AIYAH = GraphGenerator(16, 0.2, 64, (BOND_DIM, NUM_ATOMS, NUM_ATOMS), (NUM_ATOMS, ATOM_DIM), False)"
      ],
      "metadata": {
        "id": "4PETkyQlOE8A"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "holy_shit_it_works = AIYAH(sus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq-lE2Z2TFLc",
        "outputId": "b7d7c79a-fc72-4586-ebc8-a5fa69ad093c"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.04611792 -0.01190395 -0.00582716  0.02072552  0.0495905  -0.00206493\n",
            "  -0.02366902  0.01037156  0.00390775  0.00630414 -0.02273801 -0.00925849\n",
            "   0.00098659  0.011702    0.01168314  0.04228592]], shape=(1, 16), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-110-18d72db1aad0>:40: DeprecationWarning: Using a qobj for run() is deprecated as of qiskit-aer 0.9.0 and will be removed no sooner than 3 months from that release date. Transpiled circuits should now be passed directly using `backend.run(circuits, **run_options).\n",
            "  quantum_job = self.backend.run(quantum_job_object)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AIYAH.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEfRd_7-BWMj",
        "outputId": "b901f81c-e5d5-4fae-9496-a080a5e49827"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"graph_generator_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_56 (Dense)            multiple                  128       \n",
            "                                                                 \n",
            " quantum_layer_37 (QuantumLa  multiple                 1040      \n",
            " yer)                                                            \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,168\n",
            "Trainable params: 1,152\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Discriminator"
      ],
      "metadata": {
        "id": "0KR8AUItsY_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relational Graph Convolution Layer"
      ],
      "metadata": {
        "id": "TE7iqFmesmY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RelationalGraphConvLayer(keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        units=128,\n",
        "        activation=\"relu\",\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        bond_dim = input_shape[0][1]\n",
        "        atom_dim = input_shape[1][2]\n",
        "\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(bond_dim, atom_dim, self.units),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            trainable=True,\n",
        "            name=\"W\",\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=(bond_dim, 1, self.units),\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                trainable=True,\n",
        "                name=\"b\",\n",
        "                dtype=tf.float32,\n",
        "            )\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        adjacency, features = inputs\n",
        "        # Aggregate information from neighbors\n",
        "        x = tf.matmul(adjacency, features[:, None, :, :])\n",
        "        # Apply linear transformation\n",
        "        x = tf.matmul(x, self.kernel)\n",
        "        if self.use_bias:\n",
        "            x += self.bias\n",
        "        # Reduce bond types dim\n",
        "        x_reduced = tf.reduce_sum(x, axis=1)\n",
        "        # Apply non-linear transformation\n",
        "        return self.activation(x_reduced)"
      ],
      "metadata": {
        "id": "e8mcj6yKsmBn"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Actual Disciminator"
      ],
      "metadata": {
        "id": "4o9_tVWvc5la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GraphDiscriminator(\n",
        "    gconv_units, dense_units, dropout_rate, adjacency_shape, feature_shape\n",
        "):\n",
        "\n",
        "    adjacency = keras.layers.Input(shape=adjacency_shape)\n",
        "    features = keras.layers.Input(shape=feature_shape)\n",
        "\n",
        "    # Propagate through one or more graph convolutional layers\n",
        "    features_transformed = features\n",
        "    for units in gconv_units:\n",
        "        features_transformed = RelationalGraphConvLayer(units)(\n",
        "            [adjacency, features_transformed]\n",
        "        )\n",
        "\n",
        "    # Reduce 2-D representation of molecule to 1-D\n",
        "    x = keras.layers.GlobalAveragePooling1D()(features_transformed)\n",
        "\n",
        "    # Propagate through one or more densely connected layers\n",
        "    for units in dense_units:\n",
        "        x = keras.layers.Dense(units, activation=\"relu\")(x)\n",
        "        x = keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # For each molecule, output a single scalar value expressing the\n",
        "    # \"realness\" of the inputted molecule\n",
        "    x_out = keras.layers.Dense(1, dtype=\"float32\")(x)\n",
        "\n",
        "    return keras.Model(inputs=[adjacency, features], outputs=x_out)"
      ],
      "metadata": {
        "id": "EoGwuG_4ssSi"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ATOMS = 9  # Maximum number of atoms\n",
        "ATOM_DIM = 4 + 1  # Number of atom types\n",
        "BOND_DIM = 4 + 1  # Number of bond types\n",
        "LATENT_DIM = 64  # Size of the latent space"
      ],
      "metadata": {
        "id": "-g65ctOtejpv"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = GraphDiscriminator(\n",
        "    gconv_units=[128, 128, 128, 128],\n",
        "    dense_units=[512, 512],\n",
        "    dropout_rate=0.2,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")"
      ],
      "metadata": {
        "id": "-rZ45pY-d_84"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYaKlhUeem0B",
        "outputId": "d15ac981-fed2-45b1-da2a-1ce27812689c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 5, 9, 9)]    0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, 9, 5)]       0           []                               \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer (R  (None, 9, 128)      3200        ['input_6[0][0]',                \n",
            " elationalGraphConvLayer)                                         'input_7[0][0]']                \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer_1   (None, 9, 128)      81920       ['input_6[0][0]',                \n",
            " (RelationalGraphConvLayer)                                       'relational_graph_conv_layer[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer_2   (None, 9, 128)      81920       ['input_6[0][0]',                \n",
            " (RelationalGraphConvLayer)                                       'relational_graph_conv_layer_1[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer_3   (None, 9, 128)      81920       ['input_6[0][0]',                \n",
            " (RelationalGraphConvLayer)                                       'relational_graph_conv_layer_2[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 128)         0           ['relational_graph_conv_layer_3[0\n",
            " alAveragePooling1D)                                             ][0]']                           \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 512)          66048       ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 512)          0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 512)          262656      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 512)          0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1)            513         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 578,177\n",
            "Trainable params: 578,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile Final Model"
      ],
      "metadata": {
        "id": "6AhT_4VcswXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = GraphGenerator(16, 0.2, 64, (BOND_DIM, NUM_ATOMS, NUM_ATOMS), (NUM_ATOMS, ATOM_DIM), False)"
      ],
      "metadata": {
        "id": "s2ayCleBc-ok"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphWGAN(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator,\n",
        "        discriminator,\n",
        "        discriminator_steps=1,\n",
        "        generator_steps=1,\n",
        "        gp_weight=10,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.discriminator_steps = discriminator_steps\n",
        "        self.generator_steps = generator_steps\n",
        "        self.gp_weight = gp_weight\n",
        "        self.latent_dim = 64\n",
        "\n",
        "    def compile(self, optimizer_generator, optimizer_discriminator, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.optimizer_generator = optimizer_generator\n",
        "        self.optimizer_discriminator = optimizer_discriminator\n",
        "        self.metric_generator = keras.metrics.Mean(name=\"loss_gen\")\n",
        "        self.metric_discriminator = keras.metrics.Mean(name=\"loss_dis\")\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "\n",
        "        if isinstance(inputs[0], tuple):\n",
        "            inputs = inputs[0]\n",
        "\n",
        "        graph_real = inputs\n",
        "\n",
        "        self.batch_size = tf.shape(inputs[0])[0]\n",
        "\n",
        "        # Train the discriminator for one or more steps\n",
        "        for _ in range(self.discriminator_steps):\n",
        "            z = tf.random.normal((self.batch_size, self.latent_dim))\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                graph_generated = self.generator(z, training=True)\n",
        "                loss = self._loss_discriminator(graph_real, graph_generated)\n",
        "\n",
        "            grads = tape.gradient(loss, self.discriminator.trainable_weights)\n",
        "            self.optimizer_discriminator.apply_gradients(\n",
        "                zip(grads, self.discriminator.trainable_weights)\n",
        "            )\n",
        "            self.metric_discriminator.update_state(loss)\n",
        "\n",
        "        # Train the generator for one or more steps\n",
        "        for _ in range(self.generator_steps):\n",
        "            z = tf.random.normal((self.batch_size, self.latent_dim))\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                graph_generated = self.generator(z, training=True)\n",
        "                loss = self._loss_generator(graph_generated)\n",
        "\n",
        "                grads = tape.gradient(loss, self.generator.trainable_weights)\n",
        "                self.optimizer_generator.apply_gradients(\n",
        "                    zip(grads, self.generator.trainable_weights)\n",
        "                )\n",
        "                self.metric_generator.update_state(loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def _loss_discriminator(self, graph_real, graph_generated):\n",
        "        logits_real = self.discriminator(graph_real, training=True)\n",
        "        logits_generated = self.discriminator(graph_generated, training=True)\n",
        "        loss = tf.reduce_mean(logits_generated) - tf.reduce_mean(logits_real)\n",
        "        loss_gp = self._gradient_penalty(graph_real, graph_generated)\n",
        "        return loss + loss_gp * self.gp_weight\n",
        "\n",
        "    def _loss_generator(self, graph_generated):\n",
        "        logits_generated = self.discriminator(graph_generated, training=True)\n",
        "        return -tf.reduce_mean(logits_generated)\n",
        "\n",
        "    def _gradient_penalty(self, graph_real, graph_generated):\n",
        "        # Unpack graphs\n",
        "        adjacency_real, features_real = graph_real\n",
        "        adjacency_generated, features_generated = graph_generated\n",
        "\n",
        "        # Generate interpolated graphs (adjacency_interp and features_interp)\n",
        "        alpha = tf.random.uniform([self.batch_size])\n",
        "        alpha = tf.reshape(alpha, (self.batch_size, 1, 1, 1))\n",
        "        adjacency_interp = (adjacency_real * alpha) + (1 - alpha) * adjacency_generated\n",
        "        alpha = tf.reshape(alpha, (self.batch_size, 1, 1))\n",
        "        features_interp = (features_real * alpha) + (1 - alpha) * features_generated\n",
        "\n",
        "        # Compute the logits of interpolated graphs\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(adjacency_interp)\n",
        "            tape.watch(features_interp)\n",
        "            logits = self.discriminator(\n",
        "                [adjacency_interp, features_interp], training=True\n",
        "            )\n",
        "\n",
        "        # Compute the gradients with respect to the interpolated graphs\n",
        "        grads = tape.gradient(logits, [adjacency_interp, features_interp])\n",
        "        # Compute the gradient penalty\n",
        "        grads_adjacency_penalty = (1 - tf.norm(grads[0], axis=1)) ** 2\n",
        "        grads_features_penalty = (1 - tf.norm(grads[1], axis=2)) ** 2\n",
        "        return tf.reduce_mean(\n",
        "            tf.reduce_mean(grads_adjacency_penalty, axis=(-2, -1))\n",
        "            + tf.reduce_mean(grads_features_penalty, axis=(-1))\n",
        "        )"
      ],
      "metadata": {
        "id": "bZ4n7CVLsvv5"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QWGAN = GraphWGAN(generator, discriminator)"
      ],
      "metadata": {
        "id": "QpwpW78NdK_M"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QWGAN.compile(optimizer_generator=keras.optimizers.Adam(5e-4), optimizer_discriminator=keras.optimizers.Adam(5e-4),)"
      ],
      "metadata": {
        "id": "VVQ74uiMdNmU"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train this MF"
      ],
      "metadata": {
        "id": "VDkX3-pKfJcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QWGAN.fit([adjacency_tensor, feature_tensor], epochs=1, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "3Ib3BJIBe2SZ",
        "outputId": "fd190c13-804a-4798-d57c-776fb199f3dc"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-210-73416fd5b928>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQWGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madjacency_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-206-cc2a3d2f5867>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mgraph_generated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_generated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file9x448ozm.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"<ipython-input-206-cc2a3d2f5867>\", line 40, in train_step\n        graph_generated = self.generator(z, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_file9x448ozm.py\", line 10, in tf__call\n        x = ag__.converted_call(ag__.ld(self).z, (ag__.ld(input_tensor),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'graph_generator_3' (type GraphGenerator).\n    \n    in user code:\n    \n        File \"<ipython-input-199-36c917eecdd3>\", line 12, in call  *\n            x = self.z(input_tensor)\n        File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 280, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"dense_59\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 64)\n    \n    \n    Call arguments received by layer 'graph_generator_3' (type GraphGenerator):\n      â€¢ input_tensor=tf.Tensor(shape=(None, 64), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}