{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IwiXUW2Tp3jY",
        "KdTbl79Sp-Wv",
        "6N4SnjGJruEe",
        "8fn0WHxksANf",
        "vDeSpCJ5sVHg",
        "j6AQnXNbcngm",
        "dEK5YPSJEYn0",
        "42ircIwdEei9",
        "uqBFdzeu_jTw",
        "TE7iqFmesmY8",
        "6AhT_4VcswXo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install and Import"
      ],
      "metadata": {
        "id": "IwiXUW2Tp3jY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ijUUME_pvH9",
        "outputId": "bf467ab7-1108-4975-9b9d-95a2a47ace1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypi (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q rdkit pypi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem.Draw import IPythonConsole, MolsToGridImage\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "RDLogger.DisableLog(\"rdApp.*\")"
      ],
      "metadata": {
        "id": "heOJRdA2p23S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "KdTbl79Sp-Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataHelper():\n",
        "    def __init__(self):\n",
        "        csv_path = tf.keras.utils.get_file(\"qm9.csv\", \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\")\n",
        "        self.data = list()\n",
        "        with open(csv_path, \"r\")  as fin:\n",
        "            for line in fin.readlines()[1:]:\n",
        "                self.data.append(line.split(\",\")[1])\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        smiles = self.data[idx]\n",
        "        print(f\"SMILES: {smiles}\")\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        print(f\"Number of Heavy Atoms: {mol.GetNumHeavyAtoms()}\")\n",
        "        return mol"
      ],
      "metadata": {
        "id": "7ipVEFo-p_jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DH = DataHelper()"
      ],
      "metadata": {
        "id": "e8K3CcLCrTnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ce71f4-b9d9-42f9-90a9-789109aeaa06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\n",
            "29856825/29856825 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "6N4SnjGJruEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atom_mapping = {\n",
        "    \"C\": 0,\n",
        "    0: \"C\",\n",
        "    \"N\": 1,\n",
        "    1: \"N\",\n",
        "    \"O\": 2,\n",
        "    2: \"O\",\n",
        "    \"F\": 3,\n",
        "    3: \"F\",\n",
        "}\n",
        "\n",
        "bond_mapping = {\n",
        "    \"SINGLE\": 0,\n",
        "    0: Chem.BondType.SINGLE,\n",
        "    \"DOUBLE\": 1,\n",
        "    1: Chem.BondType.DOUBLE,\n",
        "    \"TRIPLE\": 2,\n",
        "    2: Chem.BondType.TRIPLE,\n",
        "    \"AROMATIC\": 3,\n",
        "    3: Chem.BondType.AROMATIC,\n",
        "}\n",
        "\n",
        "NUM_ATOMS = 9  # Maximum number of atoms\n",
        "ATOM_DIM = 4 + 1  # Number of atom types\n",
        "BOND_DIM = 4 + 1  # Number of bond types\n",
        "LATENT_DIM = 64  # Size of the latent space\n",
        "\n",
        "\n",
        "def smiles_to_graph(smiles):\n",
        "    # Converts SMILES to molecule object\n",
        "    molecule = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    # Initialize adjacency and feature tensor\n",
        "    adjacency = np.zeros((BOND_DIM, NUM_ATOMS, NUM_ATOMS), \"float32\")\n",
        "    features = np.zeros((NUM_ATOMS, ATOM_DIM), \"float32\")\n",
        "\n",
        "    # loop over each atom in molecule\n",
        "    for atom in molecule.GetAtoms():\n",
        "        i = atom.GetIdx()\n",
        "        atom_type = atom_mapping[atom.GetSymbol()]\n",
        "        features[i] = np.eye(ATOM_DIM)[atom_type]\n",
        "        # loop over one-hop neighbors\n",
        "        for neighbor in atom.GetNeighbors():\n",
        "            j = neighbor.GetIdx()\n",
        "            bond = molecule.GetBondBetweenAtoms(i, j)\n",
        "            bond_type_idx = bond_mapping[bond.GetBondType().name]\n",
        "            adjacency[bond_type_idx, [i, j], [j, i]] = 1\n",
        "\n",
        "    # Where no bond, add 1 to last channel (indicating \"non-bond\")\n",
        "    # Notice: channels-first\n",
        "    adjacency[-1, np.sum(adjacency, axis=0) == 0] = 1\n",
        "\n",
        "    # Where no atom, add 1 to last column (indicating \"non-atom\")\n",
        "    features[np.where(np.sum(features, axis=1) == 0)[0], -1] = 1\n",
        "\n",
        "    return adjacency, features\n",
        "\n",
        "\n",
        "def graph_to_molecule(graph):\n",
        "    # Unpack graph\n",
        "    adjacency, features = graph\n",
        "\n",
        "    # RWMol is a molecule object intended to be edited\n",
        "    molecule = Chem.RWMol()\n",
        "\n",
        "    # Remove \"no atoms\" & atoms with no bonds\n",
        "    keep_idx = np.where(\n",
        "        (np.argmax(features, axis=1) != ATOM_DIM - 1)\n",
        "        & (np.sum(adjacency[:-1], axis=(0, 1)) != 0)\n",
        "    )[0]\n",
        "    features = features[keep_idx]\n",
        "    adjacency = adjacency[:, keep_idx, :][:, :, keep_idx]\n",
        "\n",
        "    # Add atoms to molecule\n",
        "    for atom_type_idx in np.argmax(features, axis=1):\n",
        "        atom = Chem.Atom(atom_mapping[atom_type_idx])\n",
        "        _ = molecule.AddAtom(atom)\n",
        "\n",
        "    # Add bonds between atoms in molecule; based on the upper triangles\n",
        "    # of the [symmetric] adjacency tensor\n",
        "    (bonds_ij, atoms_i, atoms_j) = np.where(np.triu(adjacency) == 1)\n",
        "    for (bond_ij, atom_i, atom_j) in zip(bonds_ij, atoms_i, atoms_j):\n",
        "        if atom_i == atom_j or bond_ij == BOND_DIM - 1:\n",
        "            continue\n",
        "        bond_type = bond_mapping[bond_ij]\n",
        "        molecule.AddBond(int(atom_i), int(atom_j), bond_type)\n",
        "\n",
        "    # Sanitize the molecule; for more information on sanitization, see\n",
        "    # https://www.rdkit.org/docs/RDKit_Book.html#molecular-sanitization\n",
        "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
        "    # Let's be strict. If sanitization fails, return None\n",
        "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
        "        return None\n",
        "\n",
        "    return molecule"
      ],
      "metadata": {
        "id": "y0RD5YzArqgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Training Set"
      ],
      "metadata": {
        "id": "8fn0WHxksANf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_tensor, feature_tensor = [], []\n",
        "for smiles in DH.data[::10]:\n",
        "    adjacency, features = smiles_to_graph(smiles)\n",
        "    adjacency_tensor.append(adjacency)\n",
        "    feature_tensor.append(features)\n",
        "\n",
        "adjacency_tensor = np.array(adjacency_tensor)\n",
        "feature_tensor = np.array(feature_tensor)\n",
        "\n",
        "print(\"adjacency_tensor.shape =\", adjacency_tensor.shape)\n",
        "print(\"feature_tensor.shape =\", feature_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJxvQoAwr_Mm",
        "outputId": "f0fa6c57-be16-407c-ed04-eae7ff765d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adjacency_tensor.shape = (13389, 5, 9, 9)\n",
            "feature_tensor.shape = (13389, 9, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Old Generator"
      ],
      "metadata": {
        "id": "vDeSpCJ5sVHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantum LSTM Cell"
      ],
      "metadata": {
        "id": "j6AQnXNbcngm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pennylane"
      ],
      "metadata": {
        "id": "Ld_MIVqlTK25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c1e2af-a25b-478f-da06-9ab4443ac234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.31.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.6/1.4 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.22.4)\n",
            "Collecting scipy<=1.10 (from pennylane)\n",
            "  Downloading scipy-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.1)\n",
            "Collecting rustworkx (from pennylane)\n",
            "  Downloading rustworkx-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autograd<=1.5 (from pennylane)\n",
            "  Downloading autograd-1.5-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Collecting semantic-version>=2.7 (from pennylane)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting autoray>=0.3.1 (from pennylane)\n",
            "  Downloading autoray-0.6.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.3.1)\n",
            "Collecting pennylane-lightning>=0.31 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.31.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.27.1)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd<=1.5->pennylane) (0.18.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4)\n",
            "Installing collected packages: semantic-version, scipy, rustworkx, autoray, autograd, pennylane-lightning, pennylane\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: autograd\n",
            "    Found existing installation: autograd 1.6.1\n",
            "    Uninstalling autograd-1.6.1:\n",
            "      Successfully uninstalled autograd-1.6.1\n",
            "Successfully installed autograd-1.5 autoray-0.6.3 pennylane-0.31.0 pennylane-lightning-0.31.0 rustworkx-0.13.0 scipy-1.10.0 semantic-version-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml"
      ],
      "metadata": {
        "id": "w_ehYpzksX5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QLSTMCell(keras.Model):\n",
        "    def __init__(self, input_size, hidden_size, n_qubits, n_layers=1, backend=\"default.qubit\"):\n",
        "        super(QLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_layers = n_layers\n",
        "        self.backend = backend\n",
        "\n",
        "        self.wires_forget = [f\"wire_forget_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_inputs = [f\"wire_inputs_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_update = [f\"wire_update_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_output = [f\"wire_output_{i}\" for i in range(self.n_qubits)]\n",
        "\n",
        "        self.dev_forget = qml.device(self.backend, wires=self.wires_forget)\n",
        "        self.dev_inputs = qml.device(self.backend, wires=self.wires_inputs)\n",
        "        self.dev_update = qml.device(self.backend, wires=self.wires_update)\n",
        "        self.dev_output = qml.device(self.backend, wires=self.wires_output)\n",
        "\n",
        "        def _circuit_forget(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_forget)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_forget)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_forget]\n",
        "        self.qlayer_forget = qml.QNode(_circuit_forget, self.dev_forget, interface=\"tf\")\n",
        "\n",
        "        def _circuit_input(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_inputs)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_inputs, rotation=qml.RY)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_inputs]\n",
        "        self.qlayer_inputs = qml.QNode(_circuit_input, self.dev_inputs, interface=\"tf\")\n",
        "\n",
        "        def _circuit_update(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_update)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_update)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_update]\n",
        "        self.qlayer_update = qml.QNode(_circuit_update, self.dev_update, interface=\"tf\")\n",
        "\n",
        "        def _circuit_output(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_output)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_output)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_output]\n",
        "        self.qlayer_output = qml.QNode(_circuit_output, self.dev_output, interface=\"tf\")\n",
        "\n",
        "        weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
        "\n",
        "        self.cell = keras.layers.Dense(input_size + hidden_size, use_bias=True)\n",
        "        # default args = xavier_uniform for weight and zeros for bias\n",
        "\n",
        "        self.VQC = {\n",
        "            'forget': qml.qnn.KerasLayer(self.qlayer_forget, weight_shapes, n_qubits),\n",
        "            'inputs': qml.qnn.KerasLayer(self.qlayer_inputs, weight_shapes, n_qubits),\n",
        "            'update': qml.qnn.KerasLayer(self.qlayer_update, weight_shapes, n_qubits),\n",
        "            'output': qml.qnn.KerasLayer(self.qlayer_output, weight_shapes, n_qubits)\n",
        "        }\n",
        "\n",
        "        self.clayer_out = keras.layers.Dense(n_qubits, use_bias=False)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        hx, cx = hidden\n",
        "        gates = tf.concat([x, hx], axis=1)\n",
        "        gates = self.cell(gates)\n",
        "\n",
        "        for layer in range(self.n_layers):\n",
        "            ingate = keras.activations.sigmoid(self.clayer_out(self.VQC['forget'](gates)))\n",
        "            forgetgate = keras.activations.sigmoid(self.clayer_out(self.VQC['inputs'](gates)))\n",
        "            cellgate = keras.activations.tanh(self.clayer_out(self.VQC['update'](gates)))\n",
        "            outgate = keras.activations.sigmoid(self.clayer_out(self.VQC['forget'](gates)))\n",
        "\n",
        "            cy = tf.math.multiply(cx, forgetgate) + tf.math.multiply(ingate, cellgate)\n",
        "            hy = tf.math.multiply(outgate, keras.activations.tanh(cy))\n",
        "\n",
        "        return (hy, cy)\n"
      ],
      "metadata": {
        "id": "0rITPPrnS7mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QL = QLSTMCell(8, 8, 16)"
      ],
      "metadata": {
        "id": "PP4FCQvgS7od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QL([[152], [191]], [[[14003], [3356]], [[16025], [3332]]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CN6toW7akhV",
        "outputId": "286f05fd-d38e-4e10-837f-f78cac007036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 16), dtype=float32, numpy=\n",
              " array([[0.5310484 , 0.46706748, 0.49263352, 0.48885173, 0.46100816,\n",
              "         0.48616278, 0.46705902, 0.5164377 , 0.50630206, 0.47582075,\n",
              "         0.50538546, 0.45360574, 0.45882186, 0.48910308, 0.49444488,\n",
              "         0.52046955],\n",
              "        [0.50003356, 0.4988767 , 0.500993  , 0.49774396, 0.5013281 ,\n",
              "         0.49914947, 0.50132024, 0.4987475 , 0.5002066 , 0.49794322,\n",
              "         0.49889502, 0.49887583, 0.5022319 , 0.5010258 , 0.4954545 ,\n",
              "         0.49760774]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 16), dtype=float32, numpy=\n",
              " array([[8242.785 , 7791.6787, 7980.9077, 7910.351 , 7759.1963, 7918.0483,\n",
              "         7782.5093, 8119.2095, 8084.0063, 7842.506 , 8047.505 , 7697.7476,\n",
              "         7730.1973, 7930.4746, 7933.3203, 8135.8555],\n",
              "        [1672.5239, 1640.8035, 1681.1849, 1625.6139, 1688.0941, 1659.0619,\n",
              "         1676.587 , 1642.1991, 1669.8347, 1625.886 , 1653.4589, 1655.7776,\n",
              "         1700.914 , 1681.2349, 1590.5375, 1625.8953]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QL.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3u9fVzcBsc",
        "outputId": "b1cfb717-4ac7-4706-f714-d108acfb5633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"qlstm_cell\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             multiple                  48        \n",
            "                                                                 \n",
            " keras_layer (KerasLayer)    multiple                  16        \n",
            "                                                                 \n",
            " keras_layer_1 (KerasLayer)  multiple                  16        \n",
            "                                                                 \n",
            " keras_layer_3 (KerasLayer)  multiple                  16        \n",
            "                                                                 \n",
            " keras_layer_2 (KerasLayer)  multiple                  16        \n",
            "                                                                 \n",
            " dense_4 (Dense)             multiple                  256       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 368\n",
            "Trainable params: 368\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Old QLSTM Generator - VERY BUGGY"
      ],
      "metadata": {
        "id": "MzGJRlilcqDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphGenerator(keras.Model):\n",
        "    def __init__(self, H_inputs, H, z_dim, N, rw_len, temp):\n",
        "        '''\n",
        "            H_inputs: input dimension\n",
        "            H:        hidden dimension\n",
        "            z_dim:    latent dimension\n",
        "            N:        number of nodes (needed for the up and down projection)\n",
        "            rw_len:   number of LSTM cells\n",
        "            temp:     temperature for the gumbel softmax\n",
        "        '''\n",
        "        super(GraphGenerator, self).__init__()\n",
        "        self.intermediate = keras.layers.Dense(H)\n",
        "        self.c_up = keras.layers.Dense(H)\n",
        "        self.h_up = keras.layers.Dense(H)\n",
        "        self.qlstm = QLSTMCell(input_size=H_inputs, hidden_size=H, n_qubits=N)\n",
        "        self.W_up = keras.layers.Dense(N)\n",
        "        self.W_down = keras.layers.Dense(H_inputs, use_bias=False)\n",
        "        self.rw_len = rw_len\n",
        "        self.temp = temp\n",
        "        self.H, self.N = H, N\n",
        "        self.H_inputs = H_inputs\n",
        "        self.latent_dim = z_dim\n",
        "\n",
        "    def sample_latent(self, num_samples):\n",
        "        return tf.random.normal([num_samples, self.latent_dim])\n",
        "\n",
        "    # I HAVE NO IDEA HOW TO DO THIS IN TENSORFLOW\n",
        "    def init_hidden(self, batch_sz):\n",
        "        weight = next(self.parameters).data\n",
        "        return weight.new(batch_sz, self.H_inputs).zero_()\n",
        "    # HELP WITH FUNCTION ABOVE\n",
        "\n",
        "    def sample_gumbel(self, logits, eps=1e-20):\n",
        "        U = tf.random.normal([logits.shape])\n",
        "        return -tf.math.log(-tf.math.log(U + eps) + eps)\n",
        "\n",
        "    def gumbel_softmax(self, logits, temp):\n",
        "        gumbel = self.sample_gumbel(logits)\n",
        "        y = logits + gumbel\n",
        "        y = tf.nn.softmax(y / temp, axis=1)\n",
        "        return y\n",
        "\n",
        "    def call(self, latent, inputs):\n",
        "        intermediate = keras.activations.tanh(self.intermediate(latent))\n",
        "        hc = (\n",
        "            keras.activations.tanh(self.h_up(intermediate)),\n",
        "            keras.activations.tanh(self.c_up(intermediate))\n",
        "        )\n",
        "        out = []\n",
        "        for i in range(self.rw_len):\n",
        "            hh, cc = self.qlstm(inputs, hc)\n",
        "            hc = (hh, cc)\n",
        "            h_up = self.W_up(hh)\n",
        "            h_sample = self.gumbel_softmax(h_up, self.temp)\n",
        "            inputs = self.W_down(h_sample)\n",
        "            out.append(h_sample)\n",
        "        return tf.stack(out, axis=1)\n",
        "\n",
        "    def sample_reg(self, num_samples):\n",
        "        noise = self.sample_latent(num_samples)\n",
        "        inp_zeroes = self.init_hidden(num_samples)\n",
        "        gen_data = self(noise, inp_zeroes)\n",
        "        return gen_data\n",
        "\n",
        "    #Not sure if this works\n",
        "    def sample_disc(self, num_samples):\n",
        "        proba = tf.stop_gradient(self.sample_reg(num_samples))\n",
        "        return np.argmax(proba.numpy(), axis=2)\n"
      ],
      "metadata": {
        "id": "JMBKE42McsZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QG = GraphGenerator(16, 16, 16, 16, 1, 0.5)"
      ],
      "metadata": {
        "id": "NRFCejKM_Dt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QG([314.1592653], [7438, 9465])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "M_nFe1vWCDjc",
        "outputId": "318dda22-feda-41a5-de13-906bb26db202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-2213850f1ca5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m314.1592653\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7438\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9465\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-a4a893c2ea97>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, latent, inputs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mintermediate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         hc = (\n\u001b[1;32m     46\u001b[0m             \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'graph_generator_3' (type GraphGenerator).\n\nInput 0 of layer \"dense_39\" is incompatible with the layer: expected min_ndim=2, found ndim=0. Full shape received: ()\n\nCall arguments received by layer 'graph_generator_3' (type GraphGenerator):\n  â€¢ latent=['tf.Tensor(shape=(), dtype=float32)']\n  â€¢ inputs=['7438', '9465']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Generator"
      ],
      "metadata": {
        "id": "DpRa9sesBeGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantum Dense Layer"
      ],
      "metadata": {
        "id": "ne0xvdQpBaRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extra Utilities/Imports"
      ],
      "metadata": {
        "id": "dEK5YPSJEYn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q qiskit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1cwngY6CAOU",
        "outputId": "452e5ca8-c1a1-46b0-e5c1-53b0460224d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m241.5/241.5 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.5/37.5 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for qiskit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import qiskit"
      ],
      "metadata": {
        "id": "uEW8VQvzC3uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import transpile, assemble, QuantumRegister, QuantumCircuit\n",
        "from qiskit.providers.ibmq import least_busy\n",
        "from qiskit.providers.ibmq.job import job_monitor\n",
        "from qiskit.tools import backend_monitor"
      ],
      "metadata": {
        "id": "K_DritdACH6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### IDK what these functions do"
      ],
      "metadata": {
        "id": "gO0a4CqvEbIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QiskitCircuitModule:\n",
        "    def __init__(self, qubits, instructions=None, execute_on_IBMQ=False, shots=2):\n",
        "        self.qubit_num = qubits\n",
        "        self.instructions = instructions\n",
        "        if not self.instructions:\n",
        "            self.instructions = self.null_circuit(self.qubit_num)\n",
        "        self.probabilities = tf.constant([[0.5] * self.qubit_num])\n",
        "        self.phase_probabilities = tf.constant([1] * self.qubit_num)\n",
        "        self.layer = self.superposition_qubits(self.probabilities, self.phase_probabilities)\n",
        "        self.layer.append(self.instructions, range(self.qubit_num))\n",
        "        self.layer.measure_all()\n",
        "        self.backend = qiskit.Aer.get_backend('aer_simulator')\n",
        "\n",
        "    def p_to_angle(self, p):\n",
        "        angle = 2 * np.arccos(np.sqrt(p))\n",
        "        return angle\n",
        "\n",
        "    def superposition_qubits(self, probabilities: tf.Tensor, phases: tf.Tensor):\n",
        "        layer = qiskit.QuantumCircuit(self.qubit_num)\n",
        "        reshaped_probabilities = tf.reshape(probabilities, [self.qubit_num])\n",
        "        reshaped_phases = tf.reshape(phases, [self.qubit_num])\n",
        "        static_probabilities = tf.get_static_value(reshaped_probabilities[:])\n",
        "        static_phases = tf.get_static_value(reshaped_phases[:])\n",
        "        try:\n",
        "            for i in range(len(static_probabilities)):\n",
        "                p = static_probabilities[i]\n",
        "            #for ix, p in enumerate(static_probabilities):\n",
        "                p = np.abs(p)\n",
        "                theta = self.p_to_angle(p)\n",
        "                phi = self.p_to_angle(static_phases[i])\n",
        "                layer.u(theta, phi, 0, i)\n",
        "        except TypeError:\n",
        "            print(reshaped_probabilities)\n",
        "            raise RuntimeError(\"Debugging!\")\n",
        "        return layer\n",
        "\n",
        "    def quantum_execute(self, probabilities, phases):\n",
        "        self.layer = self.superposition_qubits(probabilities, phases)\n",
        "        self.layer.append(self.instructions, range(self.qubit_num))\n",
        "        self.layer.measure_all()\n",
        "        transpiled_circuit = transpile(self.layer, self.backend)\n",
        "        quantum_job_object = assemble(transpiled_circuit, shots=self.shots)\n",
        "        quantum_job = self.backend.run(quantum_job_object)\n",
        "        result = quantum_job.result().get_counts()\n",
        "        qubit_set_probabilities = self.calculate_qubit_set_probabilities(result)\n",
        "        return qubit_set_probabilities\n",
        "\n",
        "    def calculate_qubit_set_probabilities(self, quantum_job_result):\n",
        "        qubit_set_probabilities = [0] * self.qubit_num\n",
        "        for state_result, count in quantum_job_result.items():\n",
        "            for ix, q in enumerate(state_result):\n",
        "                if q == '1':\n",
        "                    qubit_set_probabilities[ix] += count\n",
        "        sum_counts = sum(qubit_set_probabilities)\n",
        "        if not sum_counts == 0:\n",
        "            qubit_set_probabilities = [i/sum_counts for i in qubit_set_probabilities]\n",
        "        return qubit_set_probabilities\n",
        "\n",
        "    def null_circuit(self, qubits):\n",
        "        try:\n",
        "            gate_register = QuantumRegister(qubits, 'q')\n",
        "            gate_circuit = QuantumCircuit(gate_register, name='sub_circuit')\n",
        "            gate_instructions = gate_circuit.to_instruction()\n",
        "        except Exception as e: raise RuntimeError(\"ğŸ…µğŸ†„ğŸ…²ğŸ…º!\")\n",
        "        return gate_instructions"
      ],
      "metadata": {
        "id": "-ZnyG8AsBjH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quantum Dense Layer"
      ],
      "metadata": {
        "id": "42ircIwdEei9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantumLayer(keras.layers.Layer):\n",
        "    def __init__(self, qubits=16, instructions=None, shots=2, use_parameter_shift_gradient_flow=False):\n",
        "        super(QuantumLayer, self).__init__()\n",
        "        self.use_parameter_shift_gradient_flow = use_parameter_shift_gradient_flow\n",
        "        self.qubits = qubits\n",
        "        self.instructions = instructions\n",
        "        self.tensor_history = []\n",
        "        self.shots = shots\n",
        "        self.circuit = QiskitCircuitModule(self.qubits, instructions=self.instructions, shots=self.shots)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        kernel_p_initialisation = tf.random_normal_initializer()\n",
        "        self.kernel_p = tf.Variable(name=\"kernel_p\", initial_value=kernel_p_initialisation(shape=(input_shape[-1], self.qubits), dtype='float32'), trainable=True)\n",
        "        kernel_phi_initialisation = tf.zeros_initializer()\n",
        "        self.kernel_phi = tf.Variable(name=\"kernel_phi\", initial_value=kernel_phi_initialisation(shape=(self.qubits,), dtype='float32'), trainable=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if not self.use_parameter_shift_gradient_flow:\n",
        "            output = tf.matmul(inputs, self.kernel_p)\n",
        "            qubit_output = self.circuit.quantum_execute(tf.reshape(output, [1, self.qubits]), self.kernel_phi)\n",
        "            qubit_output = tf.reshape(tf.convert_to_tensor(qubit_output), (1, 1, self.qubits))\n",
        "            output += (qubit_output - output)\n",
        "        else: output = self.quantum_flow(inputs)\n",
        "        return output\n",
        "\n",
        "    @tf.custom_gradient\n",
        "    def quantum_flow(self, x):\n",
        "        output = tf.matmul(x, self.kernel_p)\n",
        "        qubit_output = tf.reshape(tf.convert_to_tensor(self.circuit.quantum_execute(tf.reshape(output, [1, self.qubits]), self.kernel_phi)), (1, 1, self.qubits))\n",
        "        output = qubit_output\n",
        "\n",
        "        def grad(dy, variables=None):\n",
        "            shift = np.pi / 2\n",
        "            shift_right = x + np.ones(x.shape) * shift\n",
        "            shift_left = x - np.ones(x.shape) * shift\n",
        "            input_left = tf.matmul(shift_left, self.kernel_p)\n",
        "            input_right = tf.matmul(shift_right, self.kernel_p)\n",
        "            output_right = self.circuit.quantum_execute(tf.reshape(input_right, [1, self.qubits]), self.kernel_phi)\n",
        "            output_left = self.circuit.quantum_execute(tf.reshape(input_left, [1, self.qubits]), self.kernel_phi)\n",
        "            quantum_gradient = [output_right[i] - output_left[i] for i in range(len(output_right))]\n",
        "            input_gradient = dy * quantum_gradient\n",
        "            dy_input_gradient = tf.reshape(tf.matmul(input_gradient, tf.transpose(self.kernel_p)), shape=[1, 1, x.get_shape().as_list()[-1]])\n",
        "            grd_w = []\n",
        "            for i in range(self.qubits):\n",
        "                w = self.kernel_p[:, i]\n",
        "                w += dy_input_gradient\n",
        "                grd_w.append(w)\n",
        "            tf_grd_w = tf.convert_to_tensor(grd_w)\n",
        "            tf_grd_w = tf.reshape(tf_grd_w, shape=(x.get_shape().as_list()[-1], self.qubits))\n",
        "            return dy_input_gradient, [tf_grd_w]\n",
        "\n",
        "        return output, grad"
      ],
      "metadata": {
        "id": "BCM_W3B9Es2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Please for the love of Allah please work"
      ],
      "metadata": {
        "id": "Z_58qeXME4Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AllahuAkbar(dense_units, dropout_rate, latent_dim, adjacency_shape, feature_shape, param_shift=False,):\n",
        "        z = keras.layers.Input(shape=(64,))\n",
        "        driver = keras.layers.Dense(16, activation=\"relu\")\n",
        "        x = driver(z)\n",
        "        for units in dense_units:\n",
        "            x = QuantumLayer(units, use_parameter_shift_gradient_flow=param_shift)(x)\n",
        "            x = keras.activations.tanh()(x)\n",
        "            x = keras.layers.Dropout(dropout_rate)(x)\n",
        "        x_adjacency = keras.layers.Dense(tf.math.reduce_prod(adjacency_shape))(x)\n",
        "        x_adjacency = keras.layers.Reshape(adjacency_shape)(x_adjacency)\n",
        "        x_adjacency = (x_adjacency + tf.transpose(x_adjacency, (0, 1, 3, 2))) / 2\n",
        "        x_adjacency = keras.layers.Softmax(axis=1)(x_adjacency)\n",
        "        x_features = keras.layers.Dense(tf.math.reduce_prod(feature_shape))(x)\n",
        "        x_features = keras.layers.Reshape(feature_shape)(x_features)\n",
        "        x_features = keras.layers.Softmax(axis=2)(x_features)\n",
        "        return keras.Model(inputs=z, outputs=[x_adjacency, x_features], name=\"Allah\")"
      ],
      "metadata": {
        "id": "V9D7OblyEuVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allah = AllahuAkbar(\n",
        "    dense_units=[4, 8, 16],\n",
        "    dropout_rate=0.2,\n",
        "    latent_dim=LATENT_DIM,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")"
      ],
      "metadata": {
        "id": "R6MO70qgHMFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asdfg = tf.Tensor(\"quantum_layer_13/Reshape_1:0\", shape=(4,), dtype=float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "4pewuJ-RKORA",
        "outputId": "77745c0b-fa79-4c3a-c46d-49642d66e4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-7ddccf2020f6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masdfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quantum_layer_13/Reshape_1:0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'float32' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default Tutorial Generator - NOT QUANTUM YET"
      ],
      "metadata": {
        "id": "uqBFdzeu_jTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GraphGenerator(dense_units, dropout_rate, latent_dim, adjacency_shape, feature_shape,):\n",
        "    z = keras.layers.Input(shape=(64,))\n",
        "    x = z\n",
        "    for units in dense_units:\n",
        "        x = keras.layers.Dense(units, activation=\"tanh\")(x)\n",
        "        x = keras.layers.Dropout(dropout_rate)(x)\n",
        "    x_adjacency = keras.layers.Dense(tf.math.reduce_prod(adjacency_shape))(x)\n",
        "    x_adjacency = keras.layers.Reshape(adjacency_shape)(x_adjacency)\n",
        "    x_adjacency = (x_adjacency + tf.transpose(x_adjacency, (0, 1, 3, 2))) / 2\n",
        "    x_adjacency = keras.layers.Softmax(axis=1)(x_adjacency)\n",
        "    x_features = keras.layers.Dense(tf.math.reduce_prod(feature_shape))(x)\n",
        "    x_features = keras.layers.Reshape(feature_shape)(x_features)\n",
        "    x_features = keras.layers.Softmax(axis=2)(x_features)\n",
        "    return keras.Model(inputs=z, outputs=[x_adjacency, x_features], name=\"Generator\")"
      ],
      "metadata": {
        "id": "4kXc6r4C_mYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = GraphGenerator(\n",
        "    dense_units=[128, 256, 512],\n",
        "    dropout_rate=0.2,\n",
        "    latent_dim=LATENT_DIM,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")"
      ],
      "metadata": {
        "id": "yapQGx_CBNJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEfRd_7-BWMj",
        "outputId": "02533eb5-2dd6-4fa0-d8c4-97c44904b10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Generator\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 128)          8320        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 128)          0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 256)          33024       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 256)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 512)          131584      ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 512)          0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 405)          207765      ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 5, 9, 9)      0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose (TFOpLa  (None, 5, 9, 9)     0           ['reshape[0][0]']                \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 5, 9, 9)     0           ['reshape[0][0]',                \n",
            " da)                                                              'tf.compat.v1.transpose[0][0]'] \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 45)           23085       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.truediv (TFOpLambda)   (None, 5, 9, 9)      0           ['tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 9, 5)         0           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " softmax (Softmax)              (None, 5, 9, 9)      0           ['tf.math.truediv[0][0]']        \n",
            "                                                                                                  \n",
            " softmax_1 (Softmax)            (None, 9, 5)         0           ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 403,778\n",
            "Trainable params: 403,778\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Discriminator"
      ],
      "metadata": {
        "id": "0KR8AUItsY_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relational Graph Convolution Layer"
      ],
      "metadata": {
        "id": "TE7iqFmesmY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RelationalGraphConvLayer(keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        units=128,\n",
        "        activation=\"relu\",\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        bond_dim = input_shape[0][1]\n",
        "        atom_dim = input_shape[1][2]\n",
        "\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(bond_dim, atom_dim, self.units),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            trainable=True,\n",
        "            name=\"W\",\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=(bond_dim, 1, self.units),\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                trainable=True,\n",
        "                name=\"b\",\n",
        "                dtype=tf.float32,\n",
        "            )\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        adjacency, features = inputs\n",
        "        # Aggregate information from neighbors\n",
        "        x = tf.matmul(adjacency, features[:, None, :, :])\n",
        "        # Apply linear transformation\n",
        "        x = tf.matmul(x, self.kernel)\n",
        "        if self.use_bias:\n",
        "            x += self.bias\n",
        "        # Reduce bond types dim\n",
        "        x_reduced = tf.reduce_sum(x, axis=1)\n",
        "        # Apply non-linear transformation\n",
        "        return self.activation(x_reduced)"
      ],
      "metadata": {
        "id": "e8mcj6yKsmBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Actual Disciminator"
      ],
      "metadata": {
        "id": "4o9_tVWvc5la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GraphDiscriminator(\n",
        "    gconv_units, dense_units, dropout_rate, adjacency_shape, feature_shape\n",
        "):\n",
        "\n",
        "    adjacency = keras.layers.Input(shape=adjacency_shape)\n",
        "    features = keras.layers.Input(shape=feature_shape)\n",
        "\n",
        "    # Propagate through one or more graph convolutional layers\n",
        "    features_transformed = features\n",
        "    for units in gconv_units:\n",
        "        features_transformed = RelationalGraphConvLayer(units)(\n",
        "            [adjacency, features_transformed]\n",
        "        )\n",
        "\n",
        "    # Reduce 2-D representation of molecule to 1-D\n",
        "    x = keras.layers.GlobalAveragePooling1D()(features_transformed)\n",
        "\n",
        "    # Propagate through one or more densely connected layers\n",
        "    for units in dense_units:\n",
        "        x = keras.layers.Dense(units, activation=\"relu\")(x)\n",
        "        x = keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # For each molecule, output a single scalar value expressing the\n",
        "    # \"realness\" of the inputted molecule\n",
        "    x_out = keras.layers.Dense(1, dtype=\"float32\")(x)\n",
        "\n",
        "    return keras.Model(inputs=[adjacency, features], outputs=x_out)"
      ],
      "metadata": {
        "id": "EoGwuG_4ssSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ATOMS = 9  # Maximum number of atoms\n",
        "ATOM_DIM = 4 + 1  # Number of atom types\n",
        "BOND_DIM = 4 + 1  # Number of bond types\n",
        "LATENT_DIM = 64  # Size of the latent space"
      ],
      "metadata": {
        "id": "-g65ctOtejpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = GraphDiscriminator(\n",
        "    gconv_units=[128, 128, 128, 128],\n",
        "    dense_units=[512, 512],\n",
        "    dropout_rate=0.2,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")"
      ],
      "metadata": {
        "id": "-rZ45pY-d_84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYaKlhUeem0B",
        "outputId": "ae39a7ff-ae82-437d-b797-dfea6d8baa81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 5, 9, 9)]    0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 9, 5)]       0           []                               \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer (R  (None, 9, 128)      3200        ['input_1[0][0]',                \n",
            " elationalGraphConvLayer)                                         'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer_1   (None, 9, 128)      81920       ['input_1[0][0]',                \n",
            " (RelationalGraphConvLayer)                                       'relational_graph_conv_layer[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer_2   (None, 9, 128)      81920       ['input_1[0][0]',                \n",
            " (RelationalGraphConvLayer)                                       'relational_graph_conv_layer_1[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer_3   (None, 9, 128)      81920       ['input_1[0][0]',                \n",
            " (RelationalGraphConvLayer)                                       'relational_graph_conv_layer_2[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 128)         0           ['relational_graph_conv_layer_3[0\n",
            " alAveragePooling1D)                                             ][0]']                           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          66048       ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 512)          262656      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 512)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            513         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 578,177\n",
            "Trainable params: 578,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile Final Model - TODO"
      ],
      "metadata": {
        "id": "6AhT_4VcswXo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZ4n7CVLsvv5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}